{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34282ce4-2bae-4f6d-ad78-64617af98ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###11.4.2024\n",
    "\n",
    "###The notebook requires some initial input from the user\n",
    "###Once this information has been filled the notebook can be run\n",
    "\n",
    "planets = []  ###List of the planetary periods in days\n",
    "temp = 0 ###Temperature of the star\n",
    "\n",
    "###If you want to save arrays or values from during the run, change the respective variable to 'True'\n",
    "###Given KIC number is used to name the files\n",
    "KIC = 0\n",
    "Transit_file = False #Writes out all the transit curves to separate files\n",
    "Powerspectrum_file = False\n",
    "PSsmoothed_file = False #The smoothed power spectrum\n",
    "MFR_file = False\n",
    "Output_file = False #dv, v_max, mass, radius, luminosity and the errors\n",
    "###Fill the file destination into cell 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf0985-7dbe-427f-8dc8-77cd5ee14672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "import bisect\n",
    "import warnings\n",
    "import time as time_method\n",
    "from ps import powerspectrum\n",
    "from statistics import mean, stdev\n",
    "#from statistics import stdev\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.optimize import curve_fit\n",
    "from astropy.convolution import convolve, Box1DKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a6315-5e5d-43fd-9fcb-fd39480975fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###Array of 0/1 to pick relevant datapoints\n",
    "#Pass only 1's to consider in the next step\n",
    "def pick(x,y):\n",
    "    sx = x.copy() \n",
    "    sy = y.copy()\n",
    "    for i in range(len(index)-1,-1,-1):\n",
    "        if score[index[i]] == 0:\n",
    "            sx.pop(i)\n",
    "            sy.pop(i)\n",
    "            index.pop(i)\n",
    "    nbr_noise = 1-(len(sx))/(len(x))\n",
    "    if nbr_noise > 0.05:\n",
    "        print(\"Precentage of removed datapoints might be too high: {} with precentage {}.\".format(files, nbr_noise))\n",
    "    return sx, sy\n",
    "\n",
    "\n",
    "###Returns one scaled array\n",
    "#Creates the array of limit for each point\n",
    "def poldiff(dx,dy): \n",
    "    coeff = np.polyfit(dx,dy,3)\n",
    "    p = np.poly1d(coeff)\n",
    "    limit = [0]*len(dy)\n",
    "    for i in range(0,len(dx)):\n",
    "        limit[i] = dy[i]/p(dx[i])-1\n",
    "    cut = 5*np.median(np.absolute(limit))\n",
    "    for i in range(0,len(dx)):\n",
    "        if abs(limit[i])>=cut:\n",
    "            score[index[i]]=0\n",
    "    return limit\n",
    "    \n",
    "###Compare neighbouring points and delete if it deviates too much\n",
    "#Here is assumed that polyfit has been run and the data is centered around 0\n",
    "#Need to pass only the 1's, doesn't have a return value as it only alters the score\n",
    "def neighbour(nx,ny): \n",
    "    lcut = 4*np.median(np.absolute(ny))\n",
    "    for i in range(2,len(nx)-2):\n",
    "        if math.isnan(ny[i]) == True or math.isnan(nx[i]) == True:\n",
    "            print(\"Mistake!\")\n",
    "            continue\n",
    "        line = np.polyfit([nx[i-2],nx[i-1],nx[i+1],nx[i+2]], [ny[i-2],ny[i-1],ny[i+1],ny[i+2]], 1)\n",
    "        l = np.poly1d(line)\n",
    "        \n",
    "        if abs(abs(ny[i])-abs(l(nx[i]))) >= lcut:\n",
    "            score[i]=0\n",
    "\n",
    "###Delete the planetary transit\n",
    "def __transit__(period, tx, ty):\n",
    "    bins = int(len(tx)/500)\n",
    "    if bins < 500:\n",
    "        bins = 500\n",
    "    for i in range(0,len(tx)):\n",
    "        tx[i] = tx[i] % period\n",
    "    new = pd.DataFrame({'Time mod P':tx, 'FLux':ty})\n",
    "    quartiles = pd.qcut(new['Time mod P'], bins, labels=range(0,bins))\n",
    "    new = new.assign(Quartile=quartiles.values)\n",
    "\n",
    "    new_time = []\n",
    "    new_flux = []\n",
    "    for i in range(0,bins):\n",
    "        picked = new.loc[new['Quartile'] == i]\n",
    "        new_flux.append(picked.loc[:, 'FLux'].median())\n",
    "        new_time.append(picked.loc[:, 'Time mod P'].median())\n",
    "    return new_time, new_flux\n",
    "\n",
    "###Locate the closest transit point to substract from the data\n",
    "def find_closest(num):\n",
    "    max_index = len(new_time)\n",
    "    f_index = bisect.bisect(new_time, num)\n",
    "    if f_index < max_index:\n",
    "        if abs(new_time[f_index-1]-num) > abs(new_time[f_index]-num):\n",
    "            f_index -= 1\n",
    "    elif f_index == max_index:\n",
    "        if abs(new_time[0]-num) > abs(new_time[max_index-1]-num):\n",
    "            f_index = 0\n",
    "    return f_index\n",
    "\n",
    "###Flattening the known peaks in the data\n",
    "#To be always runned after power spectrum on Power\n",
    "#We want the following windows to flatten the peaks\n",
    "def power_peaks(): \n",
    "    flatten_peak(3964.8,3965.5)\n",
    "    flatten_peak(4531.1,4531.6)\n",
    "    flatten_peak(5097.7,5098.1)\n",
    "    flatten_peak(7876.2,7876.8)\n",
    "\n",
    "###Actually flatten the peak\n",
    "def flatten_peak(c,d): \n",
    "    Power_part = Power[round(c/step):round(d/step)]\n",
    "    med_part = np.median(Power_part)\n",
    "    while max(Power_part) > med_part:\n",
    "        Power[find_peak(round(c/step),round(d/step))] -= med_part\n",
    "        Power_part = Power[round(c/step):round(d/step)]\n",
    "        \n",
    "###Locate where the highest peak is\n",
    "def find_peak(a,b):\n",
    "    max_value = 0\n",
    "    for j in range(a,b):\n",
    "        if Power[j] > max_value:\n",
    "            max_value = Power[j] \n",
    "            max_value_index = j\n",
    "    return (max_value_index)\n",
    "\n",
    "def iscorrect():\n",
    "    #print(dv[max_index])\n",
    "    line = np.polyfit(dv[max_index-100:max_index],smooth[max_index-100:max_index],1)\n",
    "    if line[0] <= 0:\n",
    "        return False\n",
    "    line = np.polyfit(dv[max_index:max_index+100],smooth[max_index:max_index+100],1)\n",
    "    if line[0] >= 0:\n",
    "        return False\n",
    "    else: \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731d32d-ad7d-463d-bb31-fc7469c7ddda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#RUN THE WHOLE DATASET\n",
    "files_path = r\"C:\\...\\11446443\"\n",
    "read_files = glob.glob(os.path.join(files_path,\"*.dat\"))\n",
    "warnings.filterwarnings(\"ignore\") ###Might give warnings of poorly defined polynomial in the fit\n",
    "\n",
    "#Creating the dummy arrays\n",
    "time_test = []\n",
    "flux_test = []\n",
    "full_x = []\n",
    "full_y = []\n",
    "\n",
    "for files in read_files:\n",
    "    variable_table = pd.read_csv(files, delimiter='\\s+', comment='#',header=None,)\n",
    "    time_test = variable_table[variable_table.columns[:1]].to_numpy()\n",
    "    flux_test = variable_table[variable_table.columns[1:2]].to_numpy()\n",
    "    \n",
    "    lenght = len(time_test)\n",
    "    fx=[0]*lenght\n",
    "    fy=[0]*lenght\n",
    "    score=[1]*lenght\n",
    "    index = np.arange(0, lenght).tolist()\n",
    "    for i in range(0,lenght): #turning df[[]] to arrays of floats\n",
    "        fx[i] = float(time_test[i])\n",
    "        fy[i] = float(flux_test[i])\n",
    "        if np.isfinite(fy[i]) == False or math.isnan(fy[i]) == True: #Finding and removing infinities\n",
    "            score[i] = 0\n",
    "        if math.isnan(fy[i]) == True:\n",
    "            print(\"Error\")\n",
    "    \n",
    "    #For every file we correct once with polynomial and then neighboour fit\n",
    "    (fx,fy) =pick(fx,fy)\n",
    "    fy = poldiff(fx,fy) \n",
    "    (fx, fy) = pick(fx, fy)\n",
    "    neighbour(fx,fy)\n",
    "    (fx,fy) =pick(fx,fy)\n",
    "    #Gathering all the files to same list\n",
    "    full_x.extend(fx)\n",
    "    full_y.extend(fy)\n",
    "### Iterate the planetary period list\n",
    "for p in range(0,len(planets)):\n",
    "    changed_x = full_x.copy()\n",
    "    changed_y = full_y.copy()\n",
    "    (new_time,new_flux) = __transit__(planets[p],changed_x,changed_y)\n",
    "#Deleting the transit\n",
    "    for i in range(0,len(full_x)):\n",
    "        number = changed_x[i] % planets[p]\n",
    "        ind = find_closest(number)\n",
    "        full_y[i] -= new_flux[ind]\n",
    "\n",
    "    #-----------\n",
    "    min_flux = min(new_flux)\n",
    "    lowest_flux = min_flux\n",
    "    for i in range(0,len(new_flux)):\n",
    "        if new_flux[i] <= lowest_flux:\n",
    "            minimum_index = i\n",
    "\n",
    "\n",
    "    if new_time[int(0.1*len(new_flux))]>new_time[minimum_index]:\n",
    "        norm_flux = new_flux[int(0.1*len(new_flux)):]\n",
    "    elif new_time[int(0.9*len(new_flux))]<new_time[minimum_index]:\n",
    "        norm_flux = new_flux[:int(0.9*len(new_flux))]\n",
    "    else:\n",
    "        norm_flux = new_flux[:int((minimum_index-0.1*len(new_flux)))] + new_flux[int((minimum_index+0.1*len(new_flux))):]\n",
    "    median_flux = np.median(norm_flux)\n",
    "\n",
    "    lowest_flux = new_flux[(minimum_index-2):(minimum_index+2)]\n",
    "    med_point = np.median(lowest_flux)\n",
    "\n",
    "    transit_depth = median_flux-med_point\n",
    "    planet_name = ['B','C','D','E','F','G']\n",
    "    print(\"The transit depth for planet {} is {}\".format(planet_name[p],transit_depth))\n",
    "    #-----------\n",
    "\n",
    "    if Transit_file == True:\n",
    "        dfout = pd.DataFrame({'Time':new_time, 'Flux':new_flux})\n",
    "        f = open(\"transit_%d_%d.txt\" %(KIC,p+1), 'a')\n",
    "        f.write(\"# Transit curve of the planet with a period of {0} days \\n\".format(planets[p]))\n",
    "        dfout.to_csv(f)\n",
    "        f.close()\n",
    "        del dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35e7ddc-0611-422a-9af7-5c9083c456a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm = mean(full_x)\n",
    "full_x = [t - norm for t in full_x] #move around to 0\n",
    "tosix = np.array(full_x) #changind into an array x\n",
    "tosiy = np.array(full_y) #changing into an array y\n",
    "\n",
    "plt.plot(full_x, full_y)\n",
    "plt.xlabel('Time (d)')  \n",
    "plt.ylabel('Corrected flux')\n",
    "plt.title(\"Full dataset\") \n",
    "plt.show()\n",
    "\n",
    "psd = powerspectrum(tosix, tosiy)\n",
    "Fre, Power = psd.powerspectrum(scale='powerdensity')\n",
    "step = round(Fre[1]-Fre[0],8)\n",
    "\n",
    "if Powerspectrum_file == True:\n",
    "        dfout = pd.DataFrame({'Frequency':Fre, 'Power':Power})\n",
    "        f = open(\"power_%d.txt\" %(KIC), 'a')\n",
    "        dfout.to_csv(f)\n",
    "        f.close()\n",
    "        del dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9c5e8-ad92-4767-b172-a6a4f23d91e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "power_peaks()\n",
    "power_peaks() #Seems to be needed twice to make it flat\n",
    "\n",
    "plt.axis([-200, 8500, 0, 5e-10])\n",
    "#plt.axis([0, 900, 0, 5e-10])\n",
    "tgdata = gaussian_filter(Power, sigma=(6/step)/2.355)\n",
    "\n",
    "if PSsmoothed_file == True:\n",
    "        dfout = pd.DataFrame({'Frequency':Fre, 'Smoothed power':tgdata})\n",
    "        f = open(\"smoothed_power_%d.txt\" %(KIC), 'a')\n",
    "        dfout.to_csv(f)\n",
    "        f.close()\n",
    "        del dfout\n",
    "\n",
    "plt.plot(Fre, Power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baacc7c-4937-463d-8e18-0128f59432d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###MFR to find the peaks\n",
    "dv = np.arange(10,200,0.1) #create delta nu array\n",
    "dm = np.arange(0,1,0.001) #create delta m array\n",
    "mfr = np.zeros(len(dv)) #creating array of zeros\n",
    "\n",
    "for i in range(0, len(dv)):\n",
    "    total_sum = 0\n",
    "    mnull = 43.9*pow((dv[i]/100),0.295)\n",
    "    for j in range(0, len(dm)):\n",
    "        summa = 0\n",
    "        for m in range(-10, 11): #Taking 10 peaks from each side\n",
    "            step = 0.5*dv[i]*(mnull+m+dm[j])\n",
    "            index_step = round(step/0.001) #Round up to the next full index\n",
    "            summa += tgdata[index_step]\n",
    "        if summa > total_sum: #Compare if the current value is bigger than the lastest max \n",
    "            total_sum = summa\n",
    "    mfr[i] = total_sum #Save the max value per dv after varying through dm\n",
    "        \n",
    "smooth = gaussian_filter(mfr, sigma=1/0.1)/2.355\n",
    "peak = 0\n",
    "start = 200\n",
    "for i in range(start, len(dv)):\n",
    "    if smooth[i] >= peak:\n",
    "        peak = smooth[i]\n",
    "        max_index = i\n",
    "\n",
    "if MFR_file == True:\n",
    "        dfout = pd.DataFrame({'dv':dv, 'Mfr':smooth})\n",
    "        f = open(\"mfr_%d.txt\" %(KIC), 'a')\n",
    "        dfout.to_csv(f)\n",
    "        f.close()\n",
    "        del dfout\n",
    "        \n",
    "while iscorrect() == False:\n",
    "    peak = 0\n",
    "    start += 100\n",
    "    for i in range(start, len(dv)):\n",
    "        if smooth[i] >= peak:\n",
    "            peak = smooth[i]\n",
    "            max_index = i\n",
    "    if start > 1890:\n",
    "        print(\"No significant peak found\")\n",
    "        break\n",
    "\n",
    "real_nu = dv[max_index]\n",
    "real_index = max_index\n",
    "\n",
    "height = mfr[max_index] / np.mean(mfr[max_index-500:max_index+500])\n",
    "if height < 1.04:\n",
    "    print(\"The peak doesn't seem to be significant enough! The height is: \", height)\n",
    "\n",
    "\n",
    "plt.axvline(x = dv[max_index], color = 'k', linestyle='dashed', label = str(round(dv[max_index],3)) + ' µHz')\n",
    "plt.title('Smoothed Matched-filter Response')  \n",
    "plt.ylabel('MFR')  \n",
    "plt.xlabel(\"Δν\") \n",
    "leg = plt.legend(loc='upper right')\n",
    "plt.plot(dv,mfr)\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609be8df-46cb-4ac8-af93-fadeb066d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Calculating nu max with errors\n",
    "vmax = pow((dv[max_index]/0.263),(1/0.772))\n",
    "vmax_error_lower = pow((dv[max_index]/(0.263+0.009)),(1/(0.772+0.005)))\n",
    "vmax_error_upper = pow((dv[max_index]/(0.263-0.009)),(1/(0.772-0.005)))\n",
    "\n",
    "#-----\n",
    "\n",
    "step = round(Fre[1]-Fre[0],8)\n",
    "window = vmax_error_upper-vmax_error_lower\n",
    "\n",
    "\n",
    "dm_peak = Power[round((vmax-window)/step):round((vmax+window)/step):10]\n",
    "Fre_slice = Fre[round((vmax-window)/step):round((vmax+window)/step):10]\n",
    "\n",
    "#smoothed_signal = convolve(dm_peak, Box1DKernel(11)) #Smooth the sliced data\n",
    "#for i in range(0,132):\n",
    "#    smoothed_signal = convolve(smoothed_signal, Box1DKernel(11))\n",
    "sdata = gaussian_filter(dm_peak, sigma=5000) #Smooth it further\n",
    "\n",
    "bg_coeff = np.polyfit(Fre_slice,sdata,5) #fit the background\n",
    "bg_function = np.poly1d(bg_coeff)\n",
    "\n",
    "peak = 0\n",
    "for i in range(0, len(Fre_slice)):\n",
    "    if bg_function(Fre_slice[i]) >= peak:\n",
    "        peak = bg_function(Fre_slice[i])\n",
    "        max_index = i\n",
    "\n",
    "real_max = Fre_slice[max_index]\n",
    "print(\"Nu_max is {}\".format(Fre_slice[max_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce881f5d-5a1c-4f21-bc7e-925cf2f5f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creating the error bars\n",
    "#HERE WE DO THROW OUT THE LAST FEW POINTS\n",
    "partition = 4 ###How many values to compare fors errors\n",
    "partlen = math.floor(len(full_x)/partition)\n",
    "dvlist = []\n",
    "vnlist = []\n",
    "for k in range(0,partition):\n",
    "    sliced_x = tosix[k*partlen:(k+1)*partlen]\n",
    "    sliced_y = tosiy[k*partlen:(k+1)*partlen]\n",
    "\n",
    "#--------\n",
    "\n",
    "    psd = powerspectrum(sliced_x, sliced_y)\n",
    "    Fre, Power = psd.powerspectrum(scale='powerdensity')\n",
    "    step = round(Fre[1]-Fre[0],8)\n",
    "    power_peaks()\n",
    "    power_peaks()\n",
    "    #if real_max < 2000:\n",
    "        #Power_error = Power[0:round((real_max+3000)/step)]\n",
    "    #else: \n",
    "        #Power_error = Power[round((real_max-2000)/step):round((real_max+2000)/step)]\n",
    "    tgdata = gaussian_filter(Power, sigma=(6/0.001)/2.355)\n",
    "#-------------\n",
    "###MFR\n",
    "    #dv = np.arange(real_index-20,real_index+20,0.1)\n",
    "    dv = np.arange(real_nu-15,real_nu+15,0.1)\n",
    "    dm = np.arange(0,1,0.001) \n",
    "    mfr = np.zeros(len(dv)) \n",
    "\n",
    "    for i in range(0, len(dv)):\n",
    "        total_sum = 0\n",
    "        mnull = 43.9*pow((dv[i]/100),0.295)\n",
    "        for j in range(0, len(dm)):\n",
    "            summa = 0\n",
    "            for m in range(-10, 11): #Taking 10 peaks from each side\n",
    "                step = 0.5*dv[i]*(mnull+m+dm[j])\n",
    "                index_step = round(step/0.001) #Round up to the next full index\n",
    "                summa += tgdata[index_step]\n",
    "                #if index_step < len(tgdata):\n",
    "                    #summa += tgdata[index_step]\n",
    "            if summa > total_sum: #Compare if the current value is bigger than the lastest max \n",
    "                total_sum = summa\n",
    "        mfr[i] = total_sum #Save the max value per dv after varying through dm\n",
    "\n",
    "    smooth = gaussian_filter(mfr, sigma=1/0.1)/2.355\n",
    "    peak = 0\n",
    "    for i in range(0, len(dv)):\n",
    "        if smooth[i] >= peak:\n",
    "            peak = smooth[i]\n",
    "            max_index = i\n",
    "        \n",
    "    dvlist.append(dv[max_index])\n",
    "\n",
    "#----------------\n",
    "### Find the vmax value\n",
    "    vmax = pow((dv[max_index]/0.263),(1/0.772))\n",
    "    vmax_error_lower = pow((dv[max_index]/(0.263+0.009)),(1/(0.772+0.005)))\n",
    "    vmax_error_upper = pow((dv[max_index]/(0.263-0.009)),(1/(0.772-0.005)))\n",
    "\n",
    "    step = round(Fre[1]-Fre[0],8)\n",
    "    window = vmax_error_upper-vmax_error_lower\n",
    "    \n",
    "    dm_peak = Power[round((vmax-window)/step):round((vmax+window)/step):10]\n",
    "    sdata = gaussian_filter(dm_peak, sigma=50000)\n",
    "    Fre_slice = Fre[round((vmax-window)/step):round((vmax+window)/step):10]\n",
    "\n",
    "    smoothed_signal = convolve(dm_peak, Box1DKernel(11))\n",
    "    for i in range(0,132):\n",
    "        smoothed_signal = convolve(smoothed_signal, Box1DKernel(11))\n",
    "    sdata = gaussian_filter(dm_peak, sigma=5000)\n",
    "\n",
    "    bg_coeff = np.polyfit(Fre_slice,sdata,5) \n",
    "    bg_function = np.poly1d(bg_coeff)\n",
    "    peak = 0\n",
    "    for i in range(0, len(Fre_slice)):\n",
    "        if bg_function(Fre_slice[i]) >= peak:\n",
    "            peak = bg_function(Fre_slice[i])\n",
    "            max_index = i\n",
    "    vnlist.append(Fre_slice[max_index])\n",
    "   \n",
    "\n",
    "print(\"The error of delta nu is: \" ,stdev(dvlist)/math.sqrt(len(dvlist)))\n",
    "print(\"And for nu max: \" ,stdev(vnlist)/math.sqrt(len(vnlist)))\n",
    "\n",
    "print(\"The delta nu array: \" ,dvlist)\n",
    "print(\"The nu max array: \" ,vnlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c13ce-0bff-4555-afa9-170710f596ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = (real_max/3100)**3*(real_nu/134.8)**(-4)*(temp/5772)**(1.5)\n",
    "radius = (real_max/3100)*(real_nu/134.8)**(-2)*(temp/5772)**(0.5)\n",
    "luminosity = radius**2*(temp/5772)**4\n",
    "\n",
    "max_error = stdev(vnlist)/math.sqrt(len(vnlist))\n",
    "nu_error = stdev(dvlist)/math.sqrt(len(dvlist))\n",
    "\n",
    "mass_upper = ((real_max+max_error)/3100)**3*((real_nu-nu_error)/134.8)**(-4)*(temp/5772)**(1.5)-mass\n",
    "radius_upper = ((real_max+max_error)/3100)*((real_nu-nu_error)/134.8)**(-2)*(temp/5772)**(0.5)-radius\n",
    "luminosity_upper = (radius+radius_upper)**2*(temp/5772)**4-luminosity\n",
    "\n",
    "mass_lower = mass-((real_max-max_error)/3100)**3*((real_nu+nu_error)/134.8)**(-4)*(temp/5772)**(1.5)\n",
    "radius_lower = radius-((real_max-max_error)/3100)*((real_nu+nu_error)/134.8)**(-2)*(temp/5772)**(0.5)\n",
    "luminosity_lower = luminosity-(radius-radius_lower)**2*(temp/5772)**4\n",
    "\n",
    "\n",
    "print(\"The mass is {} with error of +{} and -{}\".format(mass, mass_upper, mass_lower))\n",
    "print(\"The radius is {} with error of +{} and -{}\".format(radius, radius_upper, radius_lower))\n",
    "print(\"The luminosity is {} with error of +{} and -{}\".format(luminosity, luminosity_upper, luminosity_lower))\n",
    "\n",
    "if Output_file == True:\n",
    "        f = open(\"Out_%d.txt\" %(KIC), 'a')\n",
    "        f.write(\"Delta nu is {} with the error of {} \\n\".format(real_nu,nu_error))\n",
    "        f.write(\"Nu max is {} with the error of {} \\n\".format(real_max,max_error))\n",
    "        f.write(\"The mass is {} with error of +{} and -{} \\n\".format(mass, mass_upper, mass_lower))\n",
    "        f.write(\"The radius is {} with error of +{} and -{} \\n\".format(radius, radius_upper, radius_lower))\n",
    "        f.write(\"The luminosity is {} with error of +{} and -{}\".format(luminosity, luminosity_upper, luminosity_lower))\n",
    "        f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
